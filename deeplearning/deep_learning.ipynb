{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mda2oz87hUkA",
        "outputId": "a70f5b79-00ad-464e-df61-e3205031a1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8714 - loss: 0.4401\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9658 - loss: 0.1166\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9780 - loss: 0.0747\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0490\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0359\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0820\n",
            "test_acc: 0.9789999723434448\n"
          ]
        }
      ],
      "source": [
        "\"\"\"part 1 \"\"\"\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" PART 2\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#скаляры (тензор нулевого ранга) имеет 0 осей (ndim==0)\n",
        "print(\"Skalar\")\n",
        "x = np.array(12)\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "\n",
        "#вектор (тензор первого ранга)\n",
        "print(\"Vector\")\n",
        "x = np.array([12, 3, 6, 14])\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "\n",
        "#матрица (тензор второго ранга)\n",
        "#матрица имеет две оси\n",
        "print(\"Matrix\")\n",
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "\n",
        "#тензор третьего и выше ранга\n",
        "#если упаковать матрицы в новый массив получается трёхмерный тензор\n",
        "#упаковав трёхмерный тенхор в масив, вы получите четырёхмерный тензор\n",
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]]])\n",
        "print(\"Tensor\")\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "\n",
        "# форма - кортеж чисел описывающих колличество измерений на каждой оси тензора, матрица (3,5) вектор(5), а тензор (3,3,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGxwUAW7mF0-",
        "outputId": "53cb513e-0f78-4b8f-f405-e4c7eb071d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skalar\n",
            "12\n",
            "0\n",
            "Vector\n",
            "[12  3  6 14]\n",
            "1\n",
            "Matrix\n",
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "2\n",
            "Tensor\n",
            "[[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.ndim)\n",
        "print(train_images.shape)\n",
        "print(train_images.dtype)\n",
        "\n",
        "digit = train_images[4]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "my_slice = train_images[10:100]\n",
        "print(my_slice.shape)\n",
        "\n",
        "my_slice = train_images[10:100, :, :]\n",
        "print(my_slice.shape)\n",
        "\n",
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "print(my_slice.shape)\n",
        "\n",
        "batch = train_images[:128]\n",
        "print(batch.shape)\n",
        "\n",
        "batch = train_images[128]\n",
        "print(batch.shape)\n",
        "\n",
        "n = 10\n",
        "batch = train_images[128 * n:128 * (n + 1)]\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "ZR1EfBUfpNOD",
        "outputId": "6d8009d3-86f0-4766-8e12-8b51fccfed95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 28, 28)\n",
            "(90, 28, 28)\n",
            "(90, 28, 28)\n",
            "(128, 28, 28)\n",
            "(128, 28, 28)\n",
            "(128, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "keras.layers.Dense(512, activation = 'relu')\n",
        "#output = relu(np.dot(w, input) + b)\n",
        "\n",
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "y = np.array([12, 3, 6, 14])\n",
        "\n",
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] = max(x[i, j], 0)\n",
        "  return x\n",
        "\n",
        "x = naive_relu(x)\n",
        "print(\"Naive relu:\")\n",
        "print(x)\n",
        "\n",
        "\n",
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "y = np.array([[2, 12, 2, 24, 0],\n",
        "              [8, 10, 3, 14, 1],\n",
        "              [5, 9, 4, 16, 2]])\n",
        "\n",
        "def naive_add(x,y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert x.shape == y.shape\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] += y[i, j]\n",
        "  return x\n",
        "\n",
        "x = naive_add(x,y)\n",
        "print(\"Naive add:\")\n",
        "print(x)\n",
        "\n",
        "z = x + y\n",
        "z = np.maximum(z, 0)\n",
        "print(\"Z:\")\n",
        "print(z)\n",
        "\n",
        "\n",
        "\n",
        "x = np.array([[5, 18, 12, 4, 0],\n",
        "              [6, 19, 13, 5, 1],\n",
        "              [7, 20, 14, 6, 2]])\n",
        "y = np.array([2, 12, 2, 24, 0])\n",
        "\n",
        "def naive_add_matrix_and_vector(x,y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] +=y[j]\n",
        "  return x\n",
        "\n",
        "print(\"Naive add matrix and vector:\")\n",
        "print(naive_add_matrix_and_vector(x,y))\n",
        "\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "\n",
        "z = np.maximum(x, y)\n",
        "print(\"Z:\")\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvFHT7Z4r-j5",
        "outputId": "e8d58ed4-3c3d-4980-fe6d-3906944dcb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive relu:\n",
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "Naive add:\n",
            "[[ 7 90  4 58  0]\n",
            " [14 89  6 49  2]\n",
            " [12 89  8 52  4]]\n",
            "Z:\n",
            "[[  9 102   6  82   0]\n",
            " [ 22  99   9  63   3]\n",
            " [ 17  98  12  68   6]]\n",
            "Naive add matrix and vector:\n",
            "[[ 7 30 14 28  0]\n",
            " [ 8 31 15 29  1]\n",
            " [ 9 32 16 30  2]]\n",
            "Z:\n",
            "[[[[0.76968663 0.67055651 0.96182132 ... 0.37461756 0.93919305\n",
            "    0.81782974]\n",
            "   [0.90160022 0.69663313 0.10701118 ... 0.60268944 0.71994809\n",
            "    0.99098689]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.45242493 0.25762165\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.66693493 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.95259689]\n",
            "   [0.75396339 0.65936104 0.72867953 ... 0.57817844 0.84594215\n",
            "    0.86751477]\n",
            "   [0.93432559 0.39882025 0.83419822 ... 0.76885242 0.08863411\n",
            "    0.20013044]]\n",
            "\n",
            "  [[0.71552345 0.80329759 0.96240072 ... 0.37461756 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.74565577 0.53343488 ... 0.20071113 0.71994809\n",
            "    0.33762748]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.33958533 0.246361\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.51662772 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.54985024 ... 0.54706285 0.75738268\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.11675541 ... 0.95209259 0.73733077\n",
            "    0.38363283]]\n",
            "\n",
            "  [[0.94540481 0.67055651 0.96006417 ... 0.40035834 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.69663313 0.95409973 ... 0.90942673 0.71994809\n",
            "    0.72911244]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.96066343 0.246361\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.58414362 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.7749613  ... 0.54706285 0.77436046\n",
            "    0.86751477]\n",
            "   [0.91423508 0.47907218 0.19261563 ... 0.87665995 0.85452862\n",
            "    0.55588405]]]\n",
            "\n",
            "\n",
            " [[[0.71552345 0.67055651 0.96006417 ... 0.5387753  0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.90827517 0.8703819  ... 0.81904648 0.86116932\n",
            "    0.24922662]\n",
            "   [0.8764457  0.89864151 0.97880923 ... 0.83888297 0.97625318\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.61240608 0.97159495 ... 0.84348558 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.93026081 0.60507727 ... 0.69511148 0.88073704\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.88165415 ... 0.29393639 0.73213002\n",
            "    0.75912824]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.62960895 0.93919305\n",
            "    0.63434167]\n",
            "   [0.68915088 0.69663313 0.99307256 ... 0.93762356 0.71994809\n",
            "    0.2733263 ]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.33780844 0.99246189\n",
            "    0.84597525]\n",
            "   ...\n",
            "   [0.7018814  0.75360621 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.99083859 0.79707379 0.76803776 ... 0.97340241 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.98256364 0.37420175 ... 0.51981753 0.41349992\n",
            "    0.20013044]]\n",
            "\n",
            "  [[0.75432262 0.67055651 0.96006417 ... 0.37461756 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.69663313 0.8048843  ... 0.24663076 0.71994809\n",
            "    0.46057938]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.16997112 0.32402152\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.4245458  ... 0.94694865 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.45782477 0.4914322  ... 0.85944614 0.56162291\n",
            "    0.63084987]]]\n",
            "\n",
            "\n",
            " [[[0.71552345 0.67060734 0.96006417 ... 0.37461756 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.69663313 0.93269391 ... 0.31404218 0.71994809\n",
            "    0.45898549]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.67205805 0.68069132\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.37001952 0.80107164 ... 0.54706285 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.24198829 ... 0.29393639 0.14645581\n",
            "    0.43341708]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.9584332  0.93919305\n",
            "    0.75386472]\n",
            "   [0.41101257 0.82425901 0.3509956  ... 0.46871389 0.97103802\n",
            "    0.45052546]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.19897586 0.61764183\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.73384312 0.6293888  0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.17107649 ... 0.54706285 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.45812072 ... 0.39593548 0.38690548\n",
            "    0.69264286]]\n",
            "\n",
            "  [[0.97439375 0.67055651 0.96006417 ... 0.80426301 0.93919305\n",
            "    0.63434167]\n",
            "   [0.57666335 0.69663313 0.32904013 ... 0.9307988  0.71994809\n",
            "    0.86716249]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.81631831 0.717407\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.92854945 0.75317076 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.71676784 ... 0.54706285 0.82760295\n",
            "    0.95426474]\n",
            "   [0.91423508 0.97058152 0.11451644 ... 0.32198309 0.24303345\n",
            "    0.76938319]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.9507307  0.67055651 0.96006417 ... 0.74426653 0.93919305\n",
            "    0.99848073]\n",
            "   [0.85710317 0.69663313 0.51276783 ... 0.45929858 0.71994809\n",
            "    0.54347773]\n",
            "   [0.92077586 0.89864151 0.97880923 ... 0.3065199  0.96537721\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.89528664]\n",
            "   [0.75396339 0.71560472 0.17107649 ... 0.81982443 0.70244359\n",
            "    0.86751477]\n",
            "   [0.91423508 0.59929283 0.3030564  ... 0.29393639 0.93860059\n",
            "    0.55576407]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.37461756 0.93919305\n",
            "    0.8146511 ]\n",
            "   [0.41101257 0.69663313 0.58477582 ... 0.15366816 0.71994809\n",
            "    0.66672069]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.38976211 0.50882526\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.99840099 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.75856583 0.17107649 ... 0.55979643 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.92802419 ... 0.60282804 0.6407233\n",
            "    0.42213221]]\n",
            "\n",
            "  [[0.94188502 0.67055651 0.96006417 ... 0.37461756 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.69663313 0.65628513 ... 0.88085258 0.71994809\n",
            "    0.61498817]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.85108466 0.4942617\n",
            "    0.98245438]\n",
            "   ...\n",
            "   [0.97619825 0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.3798937  ... 0.57454013 0.60942185\n",
            "    0.86751477]\n",
            "   [0.91423508 0.9443383  0.22759195 ... 0.45176764 0.4501397\n",
            "    0.99642481]]]\n",
            "\n",
            "\n",
            " [[[0.71552345 0.67055651 0.96006417 ... 0.73556144 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.90632368 0.68269945 ... 0.45228074 0.71994809\n",
            "    0.24922662]\n",
            "   [0.78995012 0.99280741 0.97880923 ... 0.2464153  0.63742896\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.71570915 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.88203063]\n",
            "   [0.75396339 0.30377715 0.4629016  ... 0.54706285 0.67320942\n",
            "    0.97967299]\n",
            "   [0.91423508 0.39882025 0.80842479 ... 0.29393639 0.10616426\n",
            "    0.60608008]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.81667305 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.69663313 0.47716257 ... 0.90338138 0.98510036\n",
            "    0.84809443]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.83794554 0.91393745\n",
            "    0.97174249]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.93201832 0.65217679 ... 0.54706285 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.70972026 0.50208999 ... 0.41905244 0.81632871\n",
            "    0.62599597]]\n",
            "\n",
            "  [[0.71552345 0.8920052  0.96006417 ... 0.47990889 0.93919305\n",
            "    0.87978188]\n",
            "   [0.66933616 0.69663313 0.7220407  ... 0.50011722 0.71994809\n",
            "    0.35124443]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.38464371 0.45178022\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.97425196 0.70631963 ... 0.61591236 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.91774796 0.57275052 ... 0.96452349 0.34185107\n",
            "    0.20013044]]]\n",
            "\n",
            "\n",
            " [[[0.71552345 0.67055651 0.96006417 ... 0.95503096 0.93919305\n",
            "    0.63434167]\n",
            "   [0.41101257 0.81728254 0.44246126 ... 0.99298226 0.71994809\n",
            "    0.46488417]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.34984659 0.75947796\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.43619672 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.47236844 0.65284424 ... 0.54706285 0.75214491\n",
            "    0.86751477]\n",
            "   [0.91423508 0.45753774 0.39492124 ... 0.68055286 0.84476423\n",
            "    0.82305228]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.37461756 0.93919305\n",
            "    0.97210729]\n",
            "   [0.87332845 0.8431824  0.83309093 ... 0.1454401  0.71994809\n",
            "    0.24922662]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.39904171 0.56258344\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.49930041 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.30377715 0.17107649 ... 0.54706285 0.58673236\n",
            "    0.86751477]\n",
            "   [0.91423508 0.39882025 0.79107777 ... 0.76208013 0.81106408\n",
            "    0.2172259 ]]\n",
            "\n",
            "  [[0.71552345 0.67055651 0.96006417 ... 0.42746714 0.93919305\n",
            "    0.63434167]\n",
            "   [0.60752965 0.69663313 0.9312232  ... 0.74815343 0.71994809\n",
            "    0.7987401 ]\n",
            "   [0.78995012 0.89864151 0.97880923 ... 0.73849052 0.70306994\n",
            "    0.73334638]\n",
            "   ...\n",
            "   [0.7018814  0.83842165 0.97159495 ... 0.82522644 0.93905108\n",
            "    0.82875427]\n",
            "   [0.75396339 0.61706256 0.17107649 ... 0.96688692 0.58673236\n",
            "    0.9445366 ]\n",
            "   [0.91423508 0.61240886 0.168161   ... 0.78623079 0.05969437\n",
            "    0.20013044]]]]\n"
          ]
        }
      ]
    }
  ]
}